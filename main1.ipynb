{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smiliyo55/psoCNN_Brain_Tumor/blob/main/main1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJTjT4PJ0tQZ"
      },
      "outputs": [],
      "source": [
        "!pip install import_ipynb\n",
        "!pip install torchsummary\n",
        "import import_ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqbZUZ6GO0le"
      },
      "outputs": [],
      "source": [
        "from psoCNN1 import psoCNN\n",
        "from population1 import Population\n",
        "import particle1\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5e4Cv0hcGNo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmiRPQcfYFXl"
      },
      "outputs": [],
      "source": [
        "# Define default values for parameters\n",
        "default_dataset = \"Brain Tumor MRI Dataset\"\n",
        "default_number_runs = 1\n",
        "default_number_iterations = 2\n",
        "default_population_size = 3\n",
        "default_batch_size_pso = 16\n",
        "default_batch_size_full_training = 16\n",
        "default_epochs_pso = 1\n",
        "default_epochs_full_training = 20\n",
        "default_max_conv_output_channels = 32\n",
        "default_max_fully_connected_neurons = 128\n",
        "default_min_layer = 3\n",
        "default_max_layer = 6\n",
        "default_probability_convolution = 0.25\n",
        "default_probability_pooling = 0.74\n",
        "default_probability_fully_connected = 0.01\n",
        "default_max_conv_kernel_size = 7\n",
        "default_Cg = 0.5\n",
        "default_dropout = 0.5\n",
        "\n",
        "# Create widgets for each parameter with larger titles\n",
        "#dataset_widget = widgets.Text(value=default_dataset, description='Dataset:', style={'description_width': 'initial'})\n",
        "number_runs_widget = widgets.IntSlider(value=default_number_runs, min=1, max=10, description='Number of Runs:', style={'description_width': 'initial'})\n",
        "number_iterations_widget = widgets.IntSlider(value=default_number_iterations, min=1, max=20, description='Number of Iterations:', style={'description_width': 'initial'})\n",
        "population_size_widget = widgets.IntSlider(value=default_population_size, min=0, max=20, description='Population Size:', style={'description_width': 'initial'})\n",
        "batch_size_pso_widget = widgets.IntSlider(value=default_batch_size_pso, min=1, max=32, description='Batch Size (PSO):', style={'description_width': 'initial'})\n",
        "batch_size_full_training_widget = widgets.IntSlider(value=default_batch_size_full_training, min=1, max=32, description='Batch Size (Full Training):', style={'description_width': 'initial'})\n",
        "epochs_pso_widget = widgets.IntSlider(value=default_epochs_pso, min=1, max=10, description='Epochs (PSO):', style={'description_width': 'initial'})\n",
        "epochs_full_training_widget = widgets.IntSlider(value=default_epochs_full_training, min=10, max=50, description='Epochs (Full Training):', style={'description_width': 'initial'})\n",
        "max_conv_output_channels_widget = widgets.IntSlider(value=default_max_conv_output_channels, min=10, max=512, description='Max Conv Output Channels:', style={'description_width': 'initial'})\n",
        "max_fully_connected_neurons_widget = widgets.IntSlider(value=default_max_fully_connected_neurons, min=10, max=512, description='Max Fully Connected Neurons:', style={'description_width': 'initial'})\n",
        "min_layer_widget = widgets.IntSlider(value=default_min_layer, min=1, max=10, description='Min Layers:', style={'description_width': 'initial'})\n",
        "max_layer_widget = widgets.IntSlider(value=default_max_layer, min=3, max=50, description='Max Layers:', style={'description_width': 'initial'})\n",
        "probability_convolution_widget = widgets.FloatSlider(value=default_probability_convolution, min=0, max=1, step=0.01, description='Probability Convolution:', style={'description_width': 'initial'})\n",
        "probability_pooling_widget = widgets.FloatSlider(value=default_probability_pooling, min=0, max=1, step=0.01, description='Probability Pooling:', style={'description_width': 'initial'})\n",
        "probability_fully_connected_widget = widgets.FloatSlider(value=default_probability_fully_connected, min=0, max=1, step=0.01, description='Probability Fully Connected:', style={'description_width': 'initial'})\n",
        "max_conv_kernel_size_widget = widgets.IntSlider(value=default_max_conv_kernel_size, min=1, max=10, description='Max Conv Kernel Size:', style={'description_width': 'initial'})\n",
        "Cg_widget = widgets.FloatSlider(value=default_Cg, min=0, max=1, step=0.1, description='Cg:', style={'description_width': 'initial'})\n",
        "dropout_widget = widgets.FloatSlider(value=default_dropout, min=0, max=1, step=0.1, description='Dropout:', style={'description_width': 'initial'})\n",
        "\n",
        "# Arrange widgets into a layout\n",
        "parameter_widgets = [ number_runs_widget, number_iterations_widget, population_size_widget,\n",
        "    batch_size_pso_widget, batch_size_full_training_widget, epochs_pso_widget, epochs_full_training_widget,\n",
        "    max_conv_output_channels_widget, max_fully_connected_neurons_widget, min_layer_widget, max_layer_widget,\n",
        "    probability_convolution_widget, probability_pooling_widget, probability_fully_connected_widget,\n",
        "    max_conv_kernel_size_widget, Cg_widget, dropout_widget\n",
        "]\n",
        "\n",
        "# Create a grid layout with two columns\n",
        "parameter_grid = widgets.GridBox(parameter_widgets, layout=widgets.Layout(grid_template_columns=\"repeat(2, 50%)\"))\n",
        "\n",
        "# Display the widgets with dataset name as title\n",
        "display(widgets.VBox([widgets.Label(value=default_dataset, style={'font-weight': 'bold', 'font-size': '20px', 'margin': 'auto', 'text-align': 'center'}),\n",
        "                      parameter_grid], layout=widgets.Layout(align_items='center')))\n",
        "#display(widgets.VBox([widgets.Label(value=default_dataset, style={'font-weight': 'bold', 'font-size': '20px'}), parameter_grid]))\n",
        "\n",
        "# Create a button widget\n",
        "#run_button = widgets.Button(description=\"Run Algorithm\")\n",
        "\n",
        "# Define a function to run the algorithm with the specified parameters\n",
        "def run_algorithm(button):\n",
        "    dataset = default_dataset\n",
        "    number_runs = number_runs_widget.value\n",
        "    number_iterations = number_iterations_widget.value\n",
        "    population_size = population_size_widget.value\n",
        "    batch_size_pso = batch_size_pso_widget.value\n",
        "    batch_size_full_training = batch_size_full_training_widget.value\n",
        "    epochs_pso = epochs_pso_widget.value\n",
        "    epochs_full_training = epochs_full_training_widget.value\n",
        "    max_conv_output_channels = max_conv_output_channels_widget.value\n",
        "    max_fully_connected_neurons = max_fully_connected_neurons_widget.value\n",
        "    min_layer = min_layer_widget.value\n",
        "    max_layer = max_layer_widget.value\n",
        "    probability_convolution = probability_convolution_widget.value\n",
        "    probability_pooling = probability_pooling_widget.value\n",
        "    probability_fully_connected = probability_fully_connected_widget.value\n",
        "    max_conv_kernel_size = max_conv_kernel_size_widget.value\n",
        "    Cg = Cg_widget.value\n",
        "    dropout = dropout_widget.value\n",
        "\n",
        "    ########### Run the algorithm ######################\n",
        "    results_path = \"/content/drive/MyDrive/Colab Notebooks/psoCNN2/results/\" + dataset + \"/\"\n",
        "\n",
        "    if not os.path.exists(results_path):\n",
        "            os.makedirs(results_path)\n",
        "\n",
        "    all_gBest_metrics = np.zeros((number_runs, 2))\n",
        "    runs_time = []\n",
        "    all_gbest_par = []\n",
        "    best_gBest_acc = 0\n",
        "\n",
        "    for i in range(number_runs):\n",
        "        print(\"Run number: \" + str(i))\n",
        "        start_time = time.time()\n",
        "\n",
        "        pso = psoCNN(dataset=dataset, n_iter=number_iterations, pop_size=population_size,\n",
        "                      batch_size=batch_size_pso, epochs=epochs_pso, min_layer=min_layer, max_layer=max_layer,\n",
        "                      conv_prob=probability_convolution, pool_prob=probability_pooling,\n",
        "                      fc_prob=probability_fully_connected, max_conv_kernel=max_conv_kernel_size,\n",
        "                      max_out_ch=max_conv_output_channels, max_fc_neurons=max_fully_connected_neurons,\n",
        "                      dropout_rate=dropout)\n",
        "\n",
        "        pso.fit(Cg=Cg, dropout_rate=dropout)\n",
        "\n",
        "        print(pso.gBest_acc)\n",
        "\n",
        "        # Plot current gBest\n",
        "        matplotlib.use('Agg')\n",
        "        plt.plot(pso.gBest_acc)\n",
        "        plt.xlabel(\"Iteration\")\n",
        "        plt.ylabel(\"gBest acc\")\n",
        "        plt.savefig(results_path + \"gBest-iter-\" + str(i) + \".png\")\n",
        "        plt.close()\n",
        "        plt.show()\n",
        "\n",
        "        print('gBest architecture: ')\n",
        "        print(pso.gBest)\n",
        "\n",
        "        np.save(results_path + \"gBest_inter_\" + str(i) + \"_acc_history.npy\", pso.gBest_acc)\n",
        "\n",
        "        np.save(results_path + \"gBest_iter_\" + str(i) + \"_test_acc_history.npy\", pso.gBest_test_acc)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        running_time = end_time - start_time\n",
        "\n",
        "        runs_time.append(running_time)\n",
        "\n",
        "        # Fully train the gBest model found\n",
        "        n_parameters, gBest_metrics = pso.fit_gBest(batch_size=batch_size_full_training, epochs=epochs_full_training, dropout_rate=dropout)\n",
        "        all_gbest_par.append(n_parameters)\n",
        "\n",
        "        # Visualize training history\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(gBest_metrics['train loss'], label='Training Loss')\n",
        "        plt.plot(gBest_metrics['val loss'], label='Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.title('Loss History')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(gBest_metrics['train accuracy'], label='Training Accuracy')\n",
        "        plt.plot(gBest_metrics['val accuracy'], label='Validation Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.title('Accuracy History')\n",
        "\n",
        "        plt.savefig(results_path + \"gBest-iter-history-\" + str(i) + \".png\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        if gBest_metrics['val accuracy'][-1] >= best_gBest_acc:\n",
        "          best_gBest_acc = gBest_metrics['val accuracy'][-1]\n",
        "          torch.save(pso.gBest.model, results_path + \"best-gBest-model\")\n",
        "\n",
        "        all_gBest_metrics[i, 0] = gBest_metrics['val loss'][-1]\n",
        "        all_gBest_metrics[i, 1] = gBest_metrics['val accuracy'][-1]\n",
        "\n",
        "        m = running_time//60\n",
        "        s = running_time%60\n",
        "        print(\"This run took: \" + str(m) + \" min \" + str(s) + \" sec\")\n",
        "\n",
        "          # Compute mean accuracy of all runs\n",
        "        all_gBest_mean_metrics = np.mean(all_gBest_metrics, axis=0)\n",
        "\n",
        "        np.save(results_path + \"/time_to_run.npy\", runs_time)\n",
        "\n",
        "        # Save all gBest metrics\n",
        "        np.save(results_path + \"/all_gBest_metrics.npy\", all_gBest_metrics)\n",
        "\n",
        "        # Save results in a text file\n",
        "        output_str = \"All gBest number of parameters: \" + str(all_gbest_par) + \"\\n\"\n",
        "        output_str = output_str + \"All gBest test accuracies: \" + str(all_gBest_metrics[:,1]) + \"\\n\"\n",
        "        output_str = output_str + \"All running times: \" + str(runs_time) + \"\\n\"\n",
        "        output_str = output_str + \"Mean loss of all runs: \" + str(all_gBest_mean_metrics[0]) + \"\\n\"\n",
        "        output_str = output_str + \"Mean accuracy of all runs: \" + str(all_gBest_mean_metrics[1]) + \"\\n\"\n",
        "\n",
        "        print(output_str)\n",
        "\n",
        "        with open(results_path + \"/final_results.txt\", \"w\") as f:\n",
        "            try:\n",
        "                print(output_str, file=f)\n",
        "            except SyntaxError:\n",
        "                print >> f, output_str\n",
        "\n",
        "# Link the button to the function\n",
        "#run_button.on_click(run_algorithm)\n",
        "\n",
        "# Center the creation of the run button\n",
        "centered_run_button_creation = widgets.VBox([widgets.Button(description=\"Run Algorithm\", layout=widgets.Layout(width='auto'))], layout=widgets.Layout(justify_content='center'))\n",
        "\n",
        "# Extract the run button from the VBox\n",
        "run_button = centered_run_button_creation.children[0]\n",
        "\n",
        "# Link the button to the function\n",
        "run_button.on_click(run_algorithm)\n",
        "\n",
        "# Center the run button horizontally at the bottom\n",
        "centered_run_button = widgets.VBox([run_button], layout=widgets.Layout(justify_content='center'))\n",
        "\n",
        "# Display the centered run button\n",
        "display(centered_run_button)\n",
        "\n",
        "# Display the button\n",
        "#display(run_button)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMz09KeTsZvL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBAs5ZW8YPWU"
      },
      "outputs": [],
      "source": [
        "dataset = \"Brain Tumor MRI Dataset\"\n",
        "number_runs = 1\n",
        "number_iterations = 10\n",
        "population_size = 20\n",
        "\n",
        "batch_size_pso = 16\n",
        "batch_size_full_training = 16\n",
        "\n",
        "epochs_pso = 1\n",
        "epochs_full_training = 20\n",
        "\n",
        "max_conv_output_channels = 18\n",
        "max_fully_connected_neurons = 150\n",
        "\n",
        "min_layer = 3\n",
        "max_layer = 10\n",
        "\n",
        "# Probability of each layer type (should sum to 1)\n",
        "probability_convolution = 0.4\n",
        "probability_pooling = 0.8\n",
        "probability_fully_connected = 0.0\n",
        "\n",
        "max_conv_kernel_size = 8\n",
        "\n",
        "Cg = 0.5\n",
        "dropout = 0.5\n",
        "\n",
        "########### Run the algorithm ######################\n",
        "results_path = \"/content/drive/MyDrive/Colab Notebooks/psoCNN2/results/\" + dataset + \"/\"\n",
        "\n",
        "if not os.path.exists(results_path):\n",
        "        os.makedirs(results_path)\n",
        "\n",
        "all_gBest_metrics = np.zeros((number_runs, 2))\n",
        "runs_time = []\n",
        "all_gbest_par = []\n",
        "best_gBest_acc = 0\n",
        "\n",
        "for i in range(number_runs):\n",
        "    print(\"Run number: \" + str(i))\n",
        "    start_time = time.time()\n",
        "\n",
        "    pso = psoCNN(dataset=dataset, n_iter=number_iterations, pop_size=population_size,\n",
        "                  batch_size=batch_size_pso, epochs=epochs_pso, min_layer=min_layer, max_layer=max_layer,\n",
        "                  conv_prob=probability_convolution, pool_prob=probability_pooling,\n",
        "                  fc_prob=probability_fully_connected, max_conv_kernel=max_conv_kernel_size,\n",
        "                  max_out_ch=max_conv_output_channels, max_fc_neurons=max_fully_connected_neurons,\n",
        "                  dropout_rate=dropout)\n",
        "\n",
        "    pso.fit(Cg=Cg, dropout_rate=dropout)\n",
        "\n",
        "    print(pso.gBest_acc)\n",
        "\n",
        "    # Plot current gBest\n",
        "    matplotlib.use('Agg')\n",
        "    plt.figure()\n",
        "    plt.plot(pso.gBest_acc)\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"gBest acc\")\n",
        "    plt.savefig(results_path + \"gBest-iter-\" + str(i) + \".png\")\n",
        "    plt.close()\n",
        "    plt.show()\n",
        "\n",
        "    print('gBest architecture: ')\n",
        "    print(pso.gBest)\n",
        "\n",
        "    np.save(results_path + \"gBest_inter_\" + str(i) + \"_acc_history.npy\", pso.gBest_acc)\n",
        "\n",
        "    np.save(results_path + \"gBest_iter_\" + str(i) + \"_test_acc_history.npy\", pso.gBest_test_acc)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    running_time = end_time - start_time\n",
        "\n",
        "    runs_time.append(running_time)\n",
        "\n",
        "    # Fully train the gBest model found\n",
        "    n_parameters, gBest_metrics = pso.fit_gBest(batch_size=batch_size_full_training, epochs=epochs_full_training, dropout_rate=dropout)\n",
        "    all_gbest_par.append(n_parameters)\n",
        "\n",
        "    np.save(results_path + \"gBest_\" + str(i) + \"_metrics.npy\", gBest_metrics)\n",
        "\n",
        "    # Visualize training history\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(gBest_metrics['train loss'], label='Training Loss')\n",
        "    plt.plot(gBest_metrics['val loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss History')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(gBest_metrics['train accuracy'], label='Training Accuracy')\n",
        "    plt.plot(gBest_metrics['val accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy History')\n",
        "\n",
        "    plt.savefig(results_path + \"gBest-iter-history-\" + str(i) + \".png\")\n",
        "    plt.tight_layout()\n",
        "    plt.close()\n",
        "    plt.show()\n",
        "\n",
        "    if gBest_metrics['val accuracy'][-1] >= best_gBest_acc:\n",
        "      best_gBest_acc = gBest_metrics['val accuracy'][-1]\n",
        "      torch.save(pso.gBest.model, results_path + \"best-gBest-model\")\n",
        "\n",
        "    torch.save(pso.gBest.model, results_path + \"gBest-model-\" + str(i))\n",
        "\n",
        "    all_gBest_metrics[i, 0] = gBest_metrics['val loss'][-1]\n",
        "    all_gBest_metrics[i, 1] = gBest_metrics['val accuracy'][-1]\n",
        "\n",
        "    m = int(running_time/60.0)\n",
        "    s = running_time%60.0\n",
        "    print(\"This run took: \" + str(m) + \" min\" + str(s) + \" sec\")\n",
        "    #print(\"This run took: \" + str(running_time) + \" sec.\")\n",
        "\n",
        "      # Compute mean accuracy of all runs\n",
        "    all_gBest_mean_metrics = np.mean(all_gBest_metrics, axis=0)\n",
        "\n",
        "    np.save(results_path + \"/time_to_run.npy\", runs_time)\n",
        "\n",
        "    # Save all gBest metrics\n",
        "    np.save(results_path + \"/all_gBest_metrics.npy\", all_gBest_metrics)\n",
        "\n",
        "    # Save results in a text file\n",
        "    output_str = \"All gBest number of parameters: \" + str(all_gbest_par) + \"\\n\"\n",
        "    output_str = output_str + \"All gBest test accuracies: \" + str(all_gBest_metrics[:,1]) + \"\\n\"\n",
        "    output_str = output_str + \"All running times: \" + str(runs_time) + \"\\n\"\n",
        "    output_str = output_str + \"Mean loss of all runs: \" + str(all_gBest_mean_metrics[0]) + \"\\n\"\n",
        "    output_str = output_str + \"Mean accuracy of all runs: \" + str(all_gBest_mean_metrics[1]) + \"\\n\"\n",
        "\n",
        "    print(output_str)\n",
        "\n",
        "    with open(results_path + \"/final_results.txt\", \"w\") as f:\n",
        "        try:\n",
        "            print(output_str, file=f)\n",
        "        except SyntaxError:\n",
        "            print >> f, output_str"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}